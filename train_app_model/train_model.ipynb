{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gym_env import FintechAppDRLEnv\n",
    "from gym_env.utils.scheduler import Scheduler,linear_decay\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "        self.input_layer = torch.nn.Linear(4,512)\n",
    "        self.hidden_1 = torch.nn.Linear(512,512)\n",
    "        self.hidden_2 = torch.nn.Linear(512,512)\n",
    "        self.output_layer = torch.nn.Linear(512,137)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = self.input_layer(input)\n",
    "        output = F.leaky_relu_(output)\n",
    "        output = self.hidden_1(output)\n",
    "        output = F.leaky_relu_(output)\n",
    "        output = self.hidden_2(output)\n",
    "        output = F.leaky_relu_(output)\n",
    "        output = self.output_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(Dataset):\n",
    "    \n",
    "    def __init__(self,batch_size:int=32,memory_len:int=250_000, *args, **kwargs):\n",
    "        self.__memory = []\n",
    "        self.__memory_len = memory_len\n",
    "        self.__batch_size = batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        memory_as_tensor = torch.tensor(self.__memory,device=device,dtype=torch.float32)\n",
    "        indexes = torch.randint(low=0,high=len(self.__memory),size=(min(self.__batch_size,len(self.__memory)),))\n",
    "        return memory_as_tensor[indexes]\n",
    "        \n",
    "    def push(self,env_output):\n",
    "        self.__memory.append([env_output])\n",
    "        if len(self.__memory) > self.__memory_len:\n",
    "            del self.__memory[0]\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return len(self.__memory) > self.__batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FintechAppDRLEnv(4)\n",
    "epsilon = Scheduler(0.1,linear_decay(500))\n",
    "target_network = Model().to(device)\n",
    "policy_network = Model().to(device)\n",
    "target_network.load_state_dict(policy_network.state_dict())\n",
    "memory = Memory()\n",
    "optimizer = torch.optim.AdamW(policy_network.parameters(),1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "target_network = target_network.eval()\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(q_values:torch.Tensor,epsilon:Scheduler):\n",
    "    if torch.rand(size=(1,)) <float(epsilon):\n",
    "        return torch.randint(high=137,size=(1,)).cpu().item()\n",
    "    return torch.argmax(q_values.clone().detach().view(-1).cpu(),dim=0).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_node = None\n",
    "for node in env._env_map.values():\n",
    "    if node.color == \"green\":\n",
    "        true_node = node\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in true_node.return_children():\n",
    "    if node.color == \"green\":\n",
    "        true_node = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joinscreen\n"
     ]
    }
   ],
   "source": [
    "print(true_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf25e7ba22e4b22b176866b4cf67866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with FALSE\n",
      "true finished count: 0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "for epoch in tqdm(range(500)):\n",
    "    done = False\n",
    "    past_observation = env.reset(seed=7)\n",
    "    ep_return = 0\n",
    "    i = 0\n",
    "    while not done:\n",
    "        i += 1\n",
    "        with torch.no_grad():\n",
    "            action = choose_action(policy_network(torch.tensor(past_observation,device=device,dtype=torch.float32)),epsilon)\n",
    "            observation, reward, terminated = env.step(action)\n",
    "            done = terminated\n",
    "            memory.push(env_output=[*observation,*past_observation,int(action), reward,terminated])\n",
    "            past_observation = observation\n",
    "        if memory:\n",
    "            for i, batch in enumerate(memory):\n",
    "                batch = batch.squeeze()\n",
    "                action_indexes = (F.one_hot(batch[:,8].view(-1,1).to(torch.int64),num_classes=137)==1).view(-1,137)\n",
    "                current_state_outputs = policy_network(batch[:,4:8])[action_indexes]\n",
    "                with torch.no_grad():\n",
    "                    next_state_outputs = target_network(batch[:,:4])\n",
    "                    next_state_outputs = torch.max(next_state_outputs,dim=1).values\n",
    "                    next_state_outputs = batch[:,9]+ ( ~(batch[:,10].to(torch.bool))*0.99*next_state_outputs)\n",
    "                    next_state_outputs = (next_state_outputs +1) / 2\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(current_state_outputs.to(device).squeeze(),next_state_outputs.to(device).squeeze())\n",
    "                writer.add_scalar('loss',loss.cpu().item(),steps)\n",
    "                writer.add_scalar('reward',ep_return,steps)\n",
    "                steps += 1\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                break\n",
    "        if i > 75:\n",
    "            break\n",
    "        ep_return += reward\n",
    "    epsilon.step()        \n",
    "    if (epoch+1)%10 == 0:\n",
    "        target_network.load_state_dict(policy_network.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teknofest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
